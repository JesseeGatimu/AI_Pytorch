import torch
import torch.nn as nn
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

penguins=sns.load_dataset("penguins").dropna()
penguins.head(5)

X=penguins[["bill_length_mm","bill_depth_mm","flipper_length_mm","body_mass_g"]]
y=penguins["species"]
le=LabelEncoder()
y=le.fit_transform(y)
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

#we convert our data into tensor
X_train=torch.tensor(X_train,dtype=torch.float32)
X_test=torch.tensor(X_test,dtype=torch.float32)
y_train=torch.tensor(y_train,dtype=torch.long)
y_test=torch.tensor(y_test,dtype=torch.long)
#now we can wrap into train dataset and test dataset
train_datasets=torch.utils.data.TensorDataset(X_train,y_train)
test_datasets=torch.utils.data.TensorDataset(X_test,y_test)
#we put our datasets into loader
train_loader=torch.utils.data.DataLoader(train_datasets,batch_size=16,shuffle=True)
test_loader=torch.utils.data.DataLoader(test_datasets,batch_size=16,shuffle=False)

class PENGUIN(nn.Module):
  def __init__(self):
    super(PENGUIN,self).__init__()
    self.fc1=nn.Linear(4,16)
    self.relu=nn.ReLU()
    self.fc2=nn.Linear(16,8)
    self.fc3=nn.Linear(8,3)

  def forward(self,x):
    x=self.fc1(x)
    x=self.relu(x)
    x=self.fc2(x)
    x=self.relu(x)
    x=self.fc3(x)
    return x  
    

model=PENGUIN()
criterion=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(),lr=0.001)

epochs=500
for epoch in range(epochs):
  for batch_X, batch_Y in train_loader:
    outputs=model(batch_X)
    loss=criterion(outputs, batch_Y)
    #backward pass
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  print(f"Epoch :: {epoch+1}/{epoch} , Loss {loss.item():.2f}")

total=0
correct=0
with torch.no_grad():
  for batch_X, batch_Y in test_loader:
    outputs=model(batch_X)
    _, predicted=torch.max(outputs,1)
    total+=batch_Y.size(0)
    correct+=(predicted==batch_Y).sum().item()
print(f" Accuracy :: {100*correct/total:.2f}%")
